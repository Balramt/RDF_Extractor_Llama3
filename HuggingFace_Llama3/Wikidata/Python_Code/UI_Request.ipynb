{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ab5ac1c9-16fe-4980-b619-f85bb9c3833b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install gradio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "976f864a-a081-4a77-bf63-98f003baeae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gradio as gr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7a9e103a-fe94-43f3-8a55-ea024707e117",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "744fbf21-63a2-46c5-8cec-725056c4db84",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0f138da0-b658-496f-8b0e-9757c60d4197",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/upb/users/b/balram/profiles/unix/cs\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Get the current working directory\n",
    "current_directory = os.getcwd()\n",
    "\n",
    "# Print the current working directory\n",
    "print(current_directory)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ca370b17-933d-40c1-a93d-415871a91bef",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-10 19:12:13.459606: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-09-10 19:12:13.484772: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-09-10 19:12:13.492542: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-09-10 19:12:13.511144: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-09-10 19:12:14.654550: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6f3cdb68-2710-49a5-83ee-f61a192d3ee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a0242541-f1ae-40c3-b4f3-6c89ce20cb8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import bitsandbytes as bnb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a9d7c743-8320-402c-9f35-0a9919d06e73",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_id = \"meta-llama/Meta-Llama-3-8B\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "35e79e3d-fdf0-4ce1-8ef5-0c32d11a8417",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a32044cb-a966-4763-aafd-2cdc018448fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The `load_in_4bit` and `load_in_8bit` arguments are deprecated and will be removed in the future versions. Please, pass a `BitsAndBytesConfig` object in `quantization_config` argument instead.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d418b6a41e54088940129f1978c4910",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load the model with 4-bit quantization\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_id,\n",
    "    load_in_4bit=True,  # Enable 4-bit quantization\n",
    "    device_map=\"auto\",  # Automatically place model layers on GPU\n",
    "    torch_dtype=torch.float16\n",
    "    #quantization_config=bnb.BnbQuantizationConfig(load_in_4bit=True)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fdd5aa71-e9ed-4307-b045-7a665128cd7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the text-generation pipeline\n",
    "text_generator = pipeline(\n",
    "    \"text-generation\", \n",
    "    model=model, \n",
    "    tokenizer=tokenizer\n",
    "    #device=0  # Use GPU 0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8fc58b25-cf6c-435f-9567-65a03090c1bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model is on: cuda:0\n"
     ]
    }
   ],
   "source": [
    "# Check if the model is on GPU or CPU\n",
    "for param in model.parameters():\n",
    "    print(f\"Model is on: {param.device}\")\n",
    "    break  # Check one parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "20bb908f-2dd3-4327-93b8-5714b33b4089",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming you have this function for generating text with a model\n",
    "def generate_text(prompt_text,model_name, max_length=1500, num_return_sequences=1):\n",
    "    if model_name == \"LLama 3\":\n",
    "    # Your pre-defined text generation logic with LLama models\n",
    "        response = text_generator(prompt_text, max_length=max_length, num_return_sequences=num_return_sequences)\n",
    "    else:\n",
    "        print(\"No model execution provided\")\n",
    "    return response  # Assuming response is a list and you want the first result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "487a2a80-82ac-4dfe-a148-ebad590eadad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_test_output(response):\n",
    "    if response and len(response) > 0:\n",
    "        generated_text = response[0].get('generated_text', '')\n",
    "        match = re.search(r'Test Output:\\s*(.*?)\\s*(?:\\n|$)', generated_text, re.DOTALL)\n",
    "        if match:\n",
    "            return match.group(1).strip()\n",
    "    return 'Output not found'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "01149275-b416-401f-a8f2-feea9ad0067c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_model_output(model_output):\n",
    "    # Initialize an empty list to store triples\n",
    "    triples = []\n",
    "    \n",
    "    # Remove leading/trailing whitespace and split the input data into lines\n",
    "    lines = [line.strip() for line in model_output.strip().split('\\n')]\n",
    "    \n",
    "    # Define the regex pattern to match triples in the format: relation(subject, object)\n",
    "    pattern = re.compile(r'(.+?)\\s*\\(([^,]+),\\s*([^)]+)\\)')\n",
    "    \n",
    "    for line in lines:\n",
    "        # Find all matches for the pattern in the line\n",
    "        matches = pattern.findall(line)\n",
    "        \n",
    "        for match in matches:\n",
    "            relation, subject, obj = match\n",
    "            # Clean up subject and object values\n",
    "            subject = subject.strip()\n",
    "            obj = obj.strip()\n",
    "            \n",
    "            # Append the extracted triple to the list\n",
    "            triples.append({\"sub\": subject, \"rel\": relation, \"obj\": obj})\n",
    "    \n",
    "    # Return the list of triples\n",
    "    return triples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c89fb5b4-f4b5-4a5f-8a72-dbbb160f4281",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to process the file and generate RDF triples\n",
    "def process_file(file_path, model_name):\n",
    "    # Read the uploaded file\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        text = file.read()\n",
    "\n",
    "    # Prompt Construction\n",
    "    prompt = f\"\"\"\n",
    "    Here is the RDF data:\n",
    "\n",
    "    {text}\n",
    "    \"\"\"\n",
    "\n",
    "    print(f\"Prompt:\\n{prompt}\")\n",
    "    \n",
    "    # Generate RDF triples using the selected model\n",
    "    model_response = generate_text(prompt,model_name, max_length=500)\n",
    "   # response = generate_text(prompt_text)\n",
    "    test_output = extract_test_output(model_response)\n",
    "    \n",
    "    # Debugging: Print the test output to ensure it's correctly extracted\n",
    "    print(\"test_output : \",test_output)\n",
    "    # Parse the test output into triples\n",
    "    triples = parse_model_output(test_output)      \n",
    "    # Debugging: Print the parsed triples to ensure they're correct\n",
    "    print(\"parsed triples : \",triples)\n",
    "    # Returning both the file content and RDF triples for display\n",
    "    #rdf_triples = parse_model_output(response)\n",
    "   # print(\"rdf_triples\",rdf_triples)\n",
    "    output = f\"\\nGenerated RDF Triples:\\n{triples}\"\n",
    "    \n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a1c7ea3-679b-4f7f-a2ff-9b466fece74d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6ce2b6ba-a230-4c3b-8a6c-059aaa930621",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gradio Interface\n",
    "with gr.Blocks() as demo:\n",
    "    gr.Markdown(\"# RDF Triple Generator\")\n",
    "    gr.Markdown(\"Upload a text file, select a model, and generate RDF triples using LLama models.\")\n",
    "\n",
    "    # File upload component with filepath type\n",
    "    file_input = gr.File(label=\"Upload Input Text File\", type=\"filepath\")\n",
    "    \n",
    "    # Dropdown menu for model selection\n",
    "    \n",
    "    selected_model = gr.Dropdown(choices=[\"LLama 3\", \"LLama 2\"], label=\"Select Model\")\n",
    "    \n",
    "    # Generate button to trigger RDF generation\n",
    "    generate_button = gr.Button(\"Generate RDF Triples\")\n",
    "    \n",
    "    # Textbox to display the generated RDF triples\n",
    "    rdf_output = gr.Textbox(label=\"Generated RDF Triples\", lines=100)\n",
    "\n",
    "    # Connect the button to the processing function\n",
    "    generate_button.click(fn=process_file, inputs=[file_input, selected_model], outputs=rdf_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c8ce042c-6c95-48b1-8f70-7f081835dd9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7860\n",
      "Running on public URL: https://47b6639efc442734d9.gradio.live\n",
      "\n",
      "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"https://47b6639efc442734d9.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt:\n",
      "\n",
      "    Here is the RDF data:\n",
      "\n",
      "    prompt_text:\n",
      "Given the following ontology and sentences, please extract the triples from the sentence according to the relations in the ontology. In the output, only include the triples in the given output format.\n",
      "CONTEXT:\n",
      "Ontology Concepts: book, literary work, author, publisher, International Standard Book Number, library, calender date, film, fictional character, writer, scientific journal, article, human, literary genre, publication, trade magazine, language, intellectual work, country, territory,\n",
      "Ontology Relations: illustrator(,human), followed_by(,), publication_date(book,), author(book,human), publisher(book,publisher), characters(literary work,fictional character), editor(trade magazine,human), place_of_publication(,), narrative_location(literary work,territory), genre(literary work,literary genre), language_of_work_or_name(literary work,language), depicts(,)\n",
      "\n",
      "Example Sentence: The Foundling and Other Tales of Prydain is a collection of short high fantasy stories for children by Lloyd Alexander and illustrator Margot Zemach.\n",
      "Example Output: illustrator(The Foundling and Other Tales of Prydain,Margot Zemach)\n",
      "\n",
      "Test Sentence: Peter and the Piskies: Cornish Folk and Fairy Tales is a 1958 anthology of 34 fairy tales from Cornwall that have been collected and retold by Ruth Manning-Sanders and illustrated by Raymond Briggs.\n",
      "Test Output:\n",
      "    \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/upb/users/b/balram/profiles/unix/cs/.local/lib/python3.12/site-packages/bitsandbytes/nn/modules.py:435: UserWarning: Input type into Linear4bit is torch.float16, but bnb_4bit_compute_dtype=torch.float32 (default). This will lead to slow inference or training speed.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_output :  illustrator(Peter and the Piskies: Cornish Folk and Fairy Tales,Raymond Briggs)\n",
      "parsed triples :  [{'sub': 'Peter and the Piskies: Cornish Folk and Fairy Tales', 'rel': 'illustrator', 'obj': 'Raymond Briggs'}]\n"
     ]
    }
   ],
   "source": [
    "# Launch the Gradio interface\n",
    "demo.launch(share=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dd59702-4831-4dd7-9737-ccc5643b69cd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a634e5fe-320f-45cf-87a1-f24537f40d6c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35f3c6c2-dfb4-4672-ae2a-9a28ee2f3f3d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c78aff87-5159-47a7-87af-51de9fb7129a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23a79832-84a0-416e-a533-fa681032b1ba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c51d33ee-779a-45dd-a402-98e6385d9c39",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fe94987-c2b8-4e58-a382-2101fc3410ce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec0792c7-0ff9-4695-894a-05e2a54fd7b5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d99aaa58-0133-43bc-8e0a-8e5ac45ab434",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fca14c4-3da9-424d-9f52-8256c8b83df6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "24a12354-23c9-49e9-9c0c-77021ba2fd48",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Please ignore below celss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "facfa555-41e9-4c12-a8b1-1d79607593e1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9d3f6c2f-9723-4fec-a140-81be3f13d0b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = [{'generated_text': '\\n    Here is the RDF data:\\n\\n    prompt_text:\\nGiven the following ontology and sentences, please extract the triples from the sentence according to the relations in the ontology. In the output, only include the triples in the given output format.\\nCONTEXT:\\nOntology Concepts: book, literary work, author, publisher, International Standard Book Number, library, calender date, film, fictional character, writer, scientific journal, article, human, literary genre, publication, trade magazine, language, intellectual work, country, territory,\\nOntology Relations: illustrator(,human), followed_by(,), publication_date(book,), author(book,human), publisher(book,publisher), characters(literary work,fictional character), editor(trade magazine,human), place_of_publication(,), narrative_location(literary work,territory), genre(literary work,literary genre), language_of_work_or_name(literary work,language), depicts(,)\\n\\nExample Sentence: The Foundling and Other Tales of Prydain is a collection of short high fantasy stories for children by Lloyd Alexander and illustrator Margot Zemach.\\nExample Output: illustrator(The Foundling and Other Tales of Prydain,Margot Zemach)\\n\\nTest Sentence: Peter and the Piskies: Cornish Folk and Fairy Tales is a 1958 anthology of 34 fairy tales from Cornwall that have been collected and retold by Ruth Manning-Sanders and illustrated by Raymond Briggs.\\nTest Output:\\n     illustrator(Peter and the Piskies: Cornish Folk and Fairy Tales,Raymond Briggs)\\n     publication_date(Peter and the Piskies: Cornish Folk and Fairy Tales,1958)\\n     author(Peter and the Piskies: Cornish Folk and Fairy Tales,Ruth Manning-Sanders)\\n     publisher(Peter and the Piskies: Cornish Folk and Fairy Tales,McMillan Publishing)\\n     characters(Peter and the Piskies: Cornish Folk and Fairy Tales,Peter)\\n     characters(Peter and the Piskies: Cornish Folk and Fairy Tales,Piskies)\\n     language_of_work_or_name(Peter and the Piskies: Cornish Folk and Fairy Tales,Cornish)\\n     language_of_work_or_name(Peter and the Piskies: Cornish Folk and Fairy Tales,English)\\n     narrative_location(Peter and the Piskies: Cornish Folk and Fairy Tales,Cornwall)\\n     genre(Peter and the Piskies: Cornish Folk and'}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d1ab8888-eace-48cf-b275-1c1cb7df93eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'generated_text': '\\n    Here is the RDF data:\\n\\n    prompt_text:\\nGiven the following ontology and sentences, please extract the triples from the sentence according to the relations in the ontology. In the output, only include the triples in the given output format.\\nCONTEXT:\\nOntology Concepts: book, literary work, author, publisher, International Standard Book Number, library, calender date, film, fictional character, writer, scientific journal, article, human, literary genre, publication, trade magazine, language, intellectual work, country, territory,\\nOntology Relations: illustrator(,human), followed_by(,), publication_date(book,), author(book,human), publisher(book,publisher), characters(literary work,fictional character), editor(trade magazine,human), place_of_publication(,), narrative_location(literary work,territory), genre(literary work,literary genre), language_of_work_or_name(literary work,language), depicts(,)\\n\\nExample Sentence: The Foundling and Other Tales of Prydain is a collection of short high fantasy stories for children by Lloyd Alexander and illustrator Margot Zemach.\\nExample Output: illustrator(The Foundling and Other Tales of Prydain,Margot Zemach)\\n\\nTest Sentence: Peter and the Piskies: Cornish Folk and Fairy Tales is a 1958 anthology of 34 fairy tales from Cornwall that have been collected and retold by Ruth Manning-Sanders and illustrated by Raymond Briggs.\\nTest Output:\\n     illustrator(Peter and the Piskies: Cornish Folk and Fairy Tales,Raymond Briggs)\\n     publication_date(Peter and the Piskies: Cornish Folk and Fairy Tales,1958)\\n     author(Peter and the Piskies: Cornish Folk and Fairy Tales,Ruth Manning-Sanders)\\n     publisher(Peter and the Piskies: Cornish Folk and Fairy Tales,McMillan Publishing)\\n     characters(Peter and the Piskies: Cornish Folk and Fairy Tales,Peter)\\n     characters(Peter and the Piskies: Cornish Folk and Fairy Tales,Piskies)\\n     language_of_work_or_name(Peter and the Piskies: Cornish Folk and Fairy Tales,Cornish)\\n     language_of_work_or_name(Peter and the Piskies: Cornish Folk and Fairy Tales,English)\\n     narrative_location(Peter and the Piskies: Cornish Folk and Fairy Tales,Cornwall)\\n     genre(Peter and the Piskies: Cornish Folk and'}]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "47079e31-020d-4522-9d45-9ed2ff191ea8",
   "metadata": {},
   "outputs": [],
   "source": [
    " # Prompt Construction\n",
    "prompt = f\"\"\"\n",
    "    Here is the RDF data:\n",
    "    Barack Hussein Obama II[a] (born August 4, 1961) is an American politician who served as the 44th president of the United States from 2009 to 2017. As a member of the Democratic Party, he was the first African-American president in U.S. history. Obama previously served as a U.S. senator representing Illinois from 2005 to 2008 and as an Illinois state senator from 1997 to 2004.\n",
    "    Obama was born in Honolulu, Hawaii. He graduated from Columbia University in 1983 with a Bachelor of Arts degree in political science and later worked as a community organizer in Chicago. In 1988, Obama enrolled in Harvard Law School, where he was the first black president of the Harvard Law Review. He became a civil rights attorney and an academic, teaching constitutional law at the University of Chicago Law School from 1992 to 2004. He also went into elective politics; Obama represented the 13th district in the Illinois Senate from 1997 until 2004, when he successfully ran for the U.S. Senate. In the 2008 presidential election, after a close primary campaign against Hillary Clinton, he was nominated by the Democratic Party for president. Obama selected Joe Biden as his running mate and defeated Republican nominee John McCain.\n",
    "    \n",
    "\n",
    "    Please parse and extract RDF-like triplets from the text. For each identified triplet, provide the output as a list of tuples.\n",
    "\n",
    "    Each tuple should follow the structure:\n",
    "    (\"Subject\", \"Predicate\", \"Object\")\n",
    "\n",
    "    Guidelines:\n",
    "    1. Ensure that each triplet has exactly three components: a subject, a predicate, and an object.\n",
    "    2. If the text mentions a fact but lacks one of these components, reformulate it or omit it to ensure the triplet is complete.\n",
    "    3. Handle various types of information, including names, locations, dates, and numerical values, in a similar format.\n",
    "\n",
    "    Examples:\n",
    "    Text: \"Obama was born in Honolulu, Hawaii. He graduated from Columbia University in 1983.\"\n",
    "\n",
    "    Example Output:\n",
    "    extracted_triplets = [\n",
    "        (\"Barack Hussein Obama II\", \"was born in\", \"Honolulu, Hawaii\"),\n",
    "        (\"Barack Hussein Obama II\", \"graduated from\", \"Columbia University\"),\n",
    "        (\"Barack Hussein Obama II\", \"graduated in\", \"1983\"),\n",
    "    ]\n",
    "\n",
    "   Example Text: \"Obama was the first African-American president in U.S. history.\"\n",
    "\n",
    "    Example Output:\n",
    "    extracted_triplets = [\n",
    "        (\"Barack Hussein Obama II\", \"was the first African-American president in\", \"U.S. history\"),\n",
    "    ]\n",
    "\n",
    "    Ensure that each extracted triplet is fully formed and logically coherent.\n",
    "    \"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "518c1889-812b-4576-9768-7a9c57fdbce0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to process the file and generate RDF triples\n",
    "def process_file(file_path, model_name):\n",
    "    # Read the uploaded file\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        text = file.read()\n",
    "\n",
    "    # Prompt Construction\n",
    "    prompt = f\"\"\"\n",
    "    Here is the RDF data:\n",
    "\n",
    "    {text}\n",
    "\n",
    "    Please parse and extract RDF-like triplets from the text. For each identified triplet, provide the output as a list of tuples.\n",
    "\n",
    "    Each tuple should follow the structure:\n",
    "    (\"Subject\", \"Predicate\", \"Object\")\n",
    "\n",
    "    Guidelines:\n",
    "    1. Ensure that each triplet has exactly three components: a subject, a predicate, and an object.\n",
    "    2. If the text mentions a fact but lacks one of these components, reformulate it or omit it to ensure the triplet is complete.\n",
    "    3. Handle various types of information, including names, locations, dates, and numerical values, in a similar format.\n",
    "\n",
    "    Examples:\n",
    "    Text: \"Obama was born in Honolulu, Hawaii. He graduated from Columbia University in 1983.\"\n",
    "\n",
    "    Output:\n",
    "    extracted_triplets = [\n",
    "        (\"Barack Hussein Obama II\", \"was born in\", \"Honolulu, Hawaii\"),\n",
    "        (\"Barack Hussein Obama II\", \"graduated from\", \"Columbia University\"),\n",
    "        (\"Barack Hussein Obama II\", \"graduated in\", \"1983\"),\n",
    "    ]\n",
    "\n",
    "    Text: \"Obama was the first African-American president in U.S. history.\"\n",
    "\n",
    "    Output:\n",
    "    extracted_triplets = [\n",
    "        (\"Barack Hussein Obama II\", \"was the first African-American president in\", \"U.S. history\"),\n",
    "    ]\n",
    "\n",
    "    Ensure that each extracted triplet is fully formed and logically coherent.\n",
    "    \"\"\"\n",
    "\n",
    "    print(f\"Prompt:\\n{prompt}\")\n",
    "\n",
    "    \n",
    "    # Generate RDF triples using the selected model\n",
    "    response = generate_text(prompt,model_name, max_length=1500)\n",
    "        # Returning both the file content and RDF triples for display\n",
    "    rdf_triples = extract_triplets(response)\n",
    "    output = f\"File Content:\\n{text}\\n\\nGenerated RDF Triples:\\n{rdf_triples}\"\n",
    "    \n",
    "    return output"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
